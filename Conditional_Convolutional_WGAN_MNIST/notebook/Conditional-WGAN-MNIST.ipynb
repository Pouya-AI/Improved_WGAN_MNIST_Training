{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad as torch_grad\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(lbl):\n",
    "    gen_lbl = torch.zeros(10)\n",
    "    gen_lbl[lbl] = 1\n",
    "    critic_lbl = torch.zeros(10,28,28)\n",
    "    critic_lbl[lbl] = 1\n",
    "    return gen_lbl,critic_lbl\n",
    "\n",
    "\n",
    "transform = T.ToTensor()\n",
    "dataset_train = MNIST(root='mnist_train',train=True,transform=transform,download=True)\n",
    "dataset_test = MNIST(root='datasets/MNIST_test',train=False,transform=transform,download=True)\n",
    "concatenated_dataset = ConcatDataset([dataset_train,dataset_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "\n",
    "        self.linear0 = nn.Sequential(\n",
    "            nn.Linear(64,2048,bias=False),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.trans_conv0 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=2048,\n",
    "                               out_channels=512,\n",
    "                               kernel_size=(4,4),\n",
    "                               stride=1\n",
    "                              ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.trans_conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=(4,4),\n",
    "                               stride=2,\n",
    "                               padding=1\n",
    "                              ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.trans_conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=(4,4),\n",
    "                               stride=2,\n",
    "                               padding=2), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.trans_conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32,\n",
    "                               out_channels=16,\n",
    "                               kernel_size=(4,4),\n",
    "                               stride=2,\n",
    "                               padding=0), \n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=1,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0,\n",
    "                      dilation=1),\n",
    "            \n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,z):\n",
    "        x = self.linear0(z)\n",
    "#         print(x.shape)\n",
    "        x = x.view(x.shape[0],x.shape[1],1,1)\n",
    "#         print(x.shape)\n",
    "        x = self.trans_conv0(x)\n",
    "#         print(x.shape)\n",
    "        x = self.trans_conv1(x)\n",
    "#         print(x.shape)\n",
    "        x = self.trans_conv2(x)\n",
    "#         print(x.shape)\n",
    "        x = self.trans_conv3(x)\n",
    "#         print(x.shape)\n",
    "        x = self.conv0(x)\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic,self).__init__()\n",
    "\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(11,32,5,2,2),\n",
    "            nn.LayerNorm([32,14,14]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(32,512,5,2,2),\n",
    "            nn.LayerNorm([512,7,7]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(512,512,5,2,2),\n",
    "            nn.LayerNorm([512,4,4]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.linear0 = nn.Linear(512,1)\n",
    "        \n",
    "    def forward(self,img):\n",
    "        x = self.conv0(img)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.avg_pool(x).flatten(1)\n",
    "        out = self.linear0(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img(args):\n",
    "    args['gen']['model'].eval()\n",
    "    with torch.no_grad():\n",
    "        img = args['gen']['model'](args['data']['constant_z']).to('cpu')\n",
    "    args['gen']['model'].train()\n",
    "    return img\n",
    "\n",
    "def wloss(critic_output,critic_output_gen):\n",
    "    return torch.mean(critic_output_gen) - torch.mean(critic_output)\n",
    "\n",
    "def reg(args,critic,critic_input,critic_input_gen):\n",
    "    \n",
    "#     imgs_shape = (28,28,1)\n",
    "    alpha = torch.rand(args['data']['batch_size'],1,1,1).to(args['device'])\n",
    "    interpolated = alpha*critic_input.data + (1-alpha)*critic_input_gen.data\n",
    "    interpolated.requires_grad = True\n",
    "    pred_interpolated = args['critic']['model'](interpolated)\n",
    "    \n",
    "    gradient = torch_grad(outputs=pred_interpolated,\n",
    "                          inputs=interpolated,\n",
    "                          grad_outputs=torch.ones(args['data']['batch_size'],1).to(args['device']),\n",
    "                          create_graph=True,\n",
    "                          retain_graph=True)[0]\n",
    "    \n",
    "    gradient_norm = torch.sqrt(torch.sum(gradient**2,dim=(2,3))+1e-12)\n",
    "    reg_value = torch.mean((gradient_norm-1)**2)\n",
    "    return args['critic']['lamda']*reg_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_critic(args,imgs,noise,gen_lbls,critic_lbls):\n",
    "    \n",
    "    args['critic']['model'].train()\n",
    "    args['gen']['model'].eval()\n",
    "    \n",
    "    gen_input = torch.cat((noise,gen_lbls),dim=1)\n",
    "    with torch.no_grad():\n",
    "        gen_output = args['gen']['model'](gen_input)\n",
    "    \n",
    "    critic_input_gen = torch.cat((gen_output,critic_lbls),dim=1)\n",
    "    critic_input = torch.cat((imgs,critic_lbls),dim=1)\n",
    "    \n",
    "    critic_output_gen = args['critic']['model'](critic_input_gen)\n",
    "    critic_output = args['critic']['model'](critic_input)\n",
    "    \n",
    "    wloss_value = wloss(critic_output,critic_output_gen)\n",
    "    reg_value = reg(args,critic_input,critic_input_gen)\n",
    "    loss_value = wloss_value + reg_value\n",
    "    loss_value.backward()\n",
    "    \n",
    "    args['critic']['optim']['algorithm'].step()\n",
    "    args['critic']['optim']['algorithm'].zero_grad()\n",
    "\n",
    "\n",
    "def train_gen(args,noise,gen_lbls,critic_lbls):\n",
    "    \n",
    "    args['critic']['model'].eval()\n",
    "    args['gen']['model'].train()\n",
    "    \n",
    "    gen_input = torch.cat((noise,gen_lbls),dim=1)\n",
    "    gen_output = args['gen']['model'](gen_input)\n",
    "    \n",
    "    critic_input_gen = torch.cat((gen_output,critic_lbls),dim=1)\n",
    "    critic_output_gen = args['critic']['model'](critic_input_gen)\n",
    "    \n",
    "    loss_value = -1*torch.mean(critic_output_gen)\n",
    "    loss_value.backward()\n",
    "    \n",
    "    args['gen']['optim']['algorithm'].step()\n",
    "    args['gen']['optim']['algorithm'].zero_grad()\n",
    "    args['critic']['model'].zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(args):\n",
    "    \n",
    "    batch_size = args['data']['batch_size']\n",
    "    z_features = args['data']['z_features']\n",
    "    ncritic = args['critic']['ncritic']\n",
    "    \n",
    "    num_iter = 0\n",
    "    for imgs,(gen_lbls,critic_lbls) in tqdm(args['data']['loader']):\n",
    "        num_iter+=1\n",
    "        \n",
    "        imgs = imgs.to(args['device'])\n",
    "        gen_lbls = gen_lbls.to(args['device'])\n",
    "        critic_lbls = critic_lbls.to(args['device'])\n",
    "        noise = torch.randn(batch_size,z_features).to(args['device'])\n",
    "        \n",
    "        train_critic(args,imgs,noise,gen_lbls,critic_lbls)\n",
    "        \n",
    "        if num_iter%ncritic == 0:\n",
    "            train_gen(args,noise,gen_lbls,critic_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    for epoch in range(*args['epochs']):\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('saving generator')\n",
    "            torch.save(args['gen']['model'].state_dict(),args['gen']['dir'])\n",
    "            print('saving critic')\n",
    "            torch.save(args['critic']['model'].state_dict(),args['critic']['dir'])\n",
    "            \n",
    "            print('saving generated images')\n",
    "            img = generate_img(args)\n",
    "            img_name = f'image_samples/generated_img_sample_epoch_{epoch+1}.pt'\n",
    "            torch.save(img,img_name)\n",
    "        \n",
    "        print(f'Epoch: {epoch}')\n",
    "        train_epoch(args)\n",
    "        args['gen']['schedular'].step()\n",
    "        args['critic']['schedular'].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'critic':{\n",
    "        'model': None,\n",
    "        'ncritic':5,\n",
    "        'optim':{\n",
    "            'algorithm':None,\n",
    "            'lr':0.0001,\n",
    "            'betas':(0.5,0.99),\n",
    "        },\n",
    "        'schedular':None,\n",
    "        'dir':'Critic.pth',\n",
    "        'load':False,\n",
    "        'lamda':10\n",
    "    },\n",
    "    'gen':{\n",
    "        'model': None,\n",
    "        'optim':{\n",
    "            'algorithm':None,\n",
    "            'lr':0.0001,\n",
    "            'betas':(0.5,0.99)\n",
    "        },\n",
    "        'schedular':None,\n",
    "        'dir':'Conditional_Convolutional_Generator.pth',\n",
    "        'load':False\n",
    "    },\n",
    "    'data':{\n",
    "        'loader': None,\n",
    "        'batch_size':64,\n",
    "        'img_shape':[1,28,28],\n",
    "        'z_features':54,\n",
    "        'constant_z':None,\n",
    "        },\n",
    "    'device':'cuda',\n",
    "    'epochs':(0,3)\n",
    "}\n",
    "\n",
    "constant_z = torch.randn(10,64)\n",
    "constant_z[:,-10:] = 0\n",
    "for i in range(0,10):\n",
    "    constant_z[i][i-10] = 1\n",
    "args['data']['constant_z'] = constant_z.to(args['device'])\n",
    "\n",
    "args['gen']['model'] = Generator().to(args['device'])\n",
    "args['critic']['model'] = Critic().to(args['device'])\n",
    "\n",
    "args['gen']['optim']['algorithm'] = optim.Adam(args['gen']['model'].parameters(),\n",
    "                        lr=args['gen']['optim']['lr'],\n",
    "                        betas=args['gen']['optim']['betas'])\n",
    "args['critic']['optim']['algorithm'] = optim.Adam(args['critic']['model'].parameters(),\n",
    "                        lr=args['critic']['optim']['lr'],\n",
    "                        betas=args['critic']['optim']['betas'])\n",
    "\n",
    "args['gen']['schedular'] = optim.lr_scheduler.ExponentialLR(args['gen']['optim']['algorithm'],gamma=0.9747)\n",
    "args['critic']['schedular'] = optim.lr_scheduler.ExponentialLR(args['critic']['optim']['algorithm'],gamma=0.9747)\n",
    "\n",
    "args['data']['loader'] = DataLoader(dataset=concatenated_dataset,\n",
    "                        batch_size=args['data']['batch_size'],\n",
    "                        shuffle=True,drop_last=True,\n",
    "                        pin_memory=True,num_workers=2)\n",
    "iter_loader = iter(args['data']['loader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-cuda]",
   "language": "python",
   "name": "conda-env-torch-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
